{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Encoder Decoder\n",
    "Inspired by https://arxiv.org/abs/1802.01817"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "params = tf.contrib.training.HParams(\n",
    "    max_string_length = 64,\n",
    "    model_n = 8,\n",
    "    \n",
    "    batch_size = 256,\n",
    "    shuffle_buffer = 10000,\n",
    "    num_epochs = 10,\n",
    "    \n",
    "    conv_n_filters = 256,\n",
    "    conv_filter_size = 3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts a string of text into a vector of char codes.\n",
    "def _text_to_codes(text_string):\n",
    "    text_string = text_string.strip()[:params.max_string_length]\n",
    "    in_array = np.array([ord(c) for c in text_string], dtype=np.uint8)\n",
    "    return in_array\n",
    "\n",
    "def byte_hot_encoding(byte_codes):\n",
    "    return tf.one_hot(byte_codes, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts a prediction back to a string.\n",
    "def _codes_to_string(codes):\n",
    "    return \"\".join((chr(min(127, c)) for c in codes))\n",
    "\n",
    "def _argmax_to_string(argmaxes):\n",
    "    return \"\".join((chr(min(127, np.argmax(c))) for c in argmaxes))\n",
    "\n",
    "def decode_text(decoded_tensor):\n",
    "    from_max = tf.argmax(decoded_tensor, axis=-1)\n",
    "    return from_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_transform_to_internal(input_data, layer_id, training_flag):\n",
    "    with tf.variable_scope(\"input_transform_%d\" % layer_id):\n",
    "      layer_outputs = [input_data]\n",
    "      for _ in range(params.model_n):\n",
    "        layer_output = tf.layers.conv1d(layer_outputs[-1],filters=params.conv_n_filters, kernel_size=params.conv_filter_size, padding=\"same\", activation=None)\n",
    "        layer_output = tf.layers.batch_normalization(layer_output, training=training_flag)\n",
    "        layer_output = tf.nn.relu(layer_output)\n",
    "        if len(layer_outputs) > 2:\n",
    "          # add residual connection\n",
    "          layer_output += layer_outputs[-2]\n",
    "        layer_outputs.append(layer_output)\n",
    "    return layer_outputs[-1]\n",
    "    \n",
    "def encoder_recursion_layer(input_data, layer_id, training_flag):\n",
    "    processed = encoder_transform_to_internal(input_data, layer_id, training_flag)\n",
    "    return tf.layers.max_pooling1d(processed, pool_size=2, strides = 2)\n",
    "\n",
    "def encoder_fully_connected(input_data):\n",
    "    with tf.variable_scope(\"encoder_fully_connected\"):\n",
    "        flattened = tf.contrib.layers.flatten(input_data)\n",
    "        layer_size = flattened.get_shape()[-1].value\n",
    "        layers_output = [flattened]\n",
    "        for _ in range(params.model_n):\n",
    "            layer_output = tf.contrib.layers.fully_connected(layers_output[-1], layer_size)\n",
    "            if len(layers_output) > 2:\n",
    "                layer_output += layers_output[-2]\n",
    "            layers_output.append(layer_output)\n",
    "    return layers_output[-1]\n",
    "    \n",
    "\n",
    "def build_encoder(input_data, training_flag):\n",
    "    data = [encoder_transform_to_internal(input_data, 0, training_flag)]\n",
    "    for i in range(1, 5):\n",
    "      data.append(encoder_recursion_layer(data[-1], i, training_flag))\n",
    "    # return encoder_fully_connected(data[-1])    \n",
    "    return data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_fully_connected(input_data):\n",
    "    with tf.variable_scope(\"decoder_fully_connected\"):\n",
    "        layer_size = input_data.get_shape()[-1].value\n",
    "        layer_outputs = [input_data]\n",
    "        for _ in range(params.model_n):\n",
    "            layer_output = tf.contrib.layers.fully_connected(layer_outputs[-1], layer_size)\n",
    "            if len(layer_outputs) > 2:\n",
    "                layer_output += layer_outputs[-2]\n",
    "            layer_outputs.append(layer_output)\n",
    "        # Unflatten data.\n",
    "        output = tf.reshape(layer_outputs[-1], shape=[-1,layer_size/params.conv_n_filters, params.conv_n_filters])\n",
    "    return output\n",
    "\n",
    "def decoder_transform_to_external(input_data, depth, layer_id, training_flag):\n",
    "    with tf.variable_scope(\"decoder_transform_%d\" % layer_id):\n",
    "      layer_outputs = [input_data]\n",
    "      for _ in range(depth):\n",
    "        layer_output = tf.layers.conv1d(layer_outputs[-1],filters=params.conv_n_filters, kernel_size=params.conv_filter_size, padding=\"same\", activation=None)\n",
    "        layer_output = tf.layers.batch_normalization(layer_output, training=training_flag)\n",
    "        layer_output = tf.nn.relu(layer_output)\n",
    "        # Extend size \n",
    "        if len(layer_outputs) > 2:\n",
    "          # add residual connection\n",
    "          layer_output += layer_outputs[-2]\n",
    "        layer_outputs.append(layer_output)\n",
    "    return layer_outputs[-1]\n",
    "\n",
    "def decoder_recursion_layer(input_data, layer_id, training_flag):\n",
    "    with tf.variable_scope(\"decoder_expansion_%d\" % layer_id):\n",
    "        processed = decoder_transform_to_external(input_data, params.model_n-1,layer_id, training_flag)\n",
    "        # Expand convolution.\n",
    "        expanded = tf.layers.conv1d(processed,filters=2*params.conv_n_filters, kernel_size=params.conv_filter_size, padding=\"same\", activation=None)\n",
    "        expanded = tf.layers.batch_normalization(expanded, training=training_flag)\n",
    "        expanded = tf.nn.relu(expanded)\n",
    "        # Un-sampling is done by resize.\n",
    "        expanded_shape = expanded.get_shape()\n",
    "        expanded = tf.reshape(expanded, shape = [-1,expanded_shape[1].value*2,expanded_shape[2].value/2])\n",
    "        return expanded\n",
    "\n",
    "def build_decoder(output_data, training_flag):\n",
    "    #data = [decoder_fully_connected(output_data)]\n",
    "    data = [output_data]\n",
    "    for i in range(5,1, -1):\n",
    "        data.append(decoder_recursion_layer(data[-1], i, training_flag))\n",
    "    return decoder_transform_to_external(data[-1], params.model_n, 0, training_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.Graph().as_default():\n",
    "    dataset = tf.contrib.data.TextLineDataset(\"train.en\")\n",
    "    dataset = dataset.repeat(params.num_epochs)\n",
    "    dataset = dataset.shuffle(params.shuffle_buffer)\n",
    "    dataset = dataset.map(lambda text_string: tf.py_func(_text_to_codes,[text_string], tf.uint8))\n",
    "    dataset = dataset.padded_batch(params.batch_size, [params.max_string_length])\n",
    "    dataset = dataset.map(byte_hot_encoding)\n",
    "    training_iterator = dataset.make_initializable_iterator()\n",
    "    training_flag = tf.placeholder(tf.bool, shape=(), name=\"training_flag\")\n",
    "    next_element = training_iterator.get_next()\n",
    "    encoded = build_encoder(next_element, training_flag)\n",
    "    predicted = build_decoder(encoded, training_flag)\n",
    "    predicted_text = decode_text(predicted)\n",
    "    loss = tf.losses.softmax_cross_entropy(tf.reshape(next_element, shape=[-1,256]), tf.reshape(predicted, shape=[-1, 256]))\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    global_step = tf.Variable(0, trainable=False, name=\"global_step\")\n",
    "    exponential_decay_fn = functools.partial(\n",
    "      tf.train.exponential_decay,\n",
    "      decay_steps=10000,\n",
    "      decay_rate=0.5,\n",
    "      staircase=True)\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        training_op = tf.contrib.layers.optimize_loss(\n",
    "            loss,\n",
    "            global_step,\n",
    "            learning_rate=None,\n",
    "            optimizer=optimizer,\n",
    "            learning_rate_decay_fn=exponential_decay_fn)\n",
    "    scaffold = tf.train.Scaffold(\n",
    "        local_init_op=tf.group(tf.local_variables_initializer(),training_iterator.initializer),\n",
    "        init_op=tf.global_variables_initializer())\n",
    "    with tf.train.MonitoredTrainingSession(checkpoint_dir=\"./checkpoint\",scaffold=scaffold, save_checkpoint_secs=120, save_summaries_secs=60) as sess:\n",
    "        print \"Start training\"\n",
    "        while not sess.should_stop():\n",
    "            o_loss, _, o_step = sess.run([loss, training_op, global_step],  {training_flag:True})\n",
    "            if o_step%100 == 1:\n",
    "                clear_output(True)\n",
    "                output_string = \"\"\"Loss {0}, step {1} <BR><table>\n",
    "                <tr><th>Source</th><th>Decoded</th></tr>\"\"\".format(o_loss, o_step)\n",
    "                o_source_text, o_predicted_text = sess.run([next_element, predicted_text], {training_flag:False})\n",
    "                for t_source, t_predicted in zip((x for x in o_source_text),(y for y in o_predicted_text)):\n",
    "                    output_string += \"\"\"<tr><td>{source}</td><td>{decoded}</td></tr>\"\"\".format(source=_argmax_to_string(t_source),\n",
    "                                                                                               decoded=_codes_to_string(t_predicted))\n",
    "                output_string += \"</table>\"\n",
    "                display(HTML(output_string))\n",
    "                \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
