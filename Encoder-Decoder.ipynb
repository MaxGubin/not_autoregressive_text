{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Encoder Decoder\n",
    "Inspired by https://arxiv.org/abs/1802.01817"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from IPython.display import clear_output, display_html\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "params = tf.contrib.training.HParams(\n",
    "    max_string_length = 64,\n",
    "    model_n = 8,\n",
    "    \n",
    "    batch_size = 16,\n",
    "    shuffle_buffer = 10000,\n",
    "    num_epochs = 10,\n",
    "    \n",
    "    conv_n_filters = 256,\n",
    "    conv_filter_size = 3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts a string of text into a vector of char codes.\n",
    "def _text_to_codes(text_string):\n",
    "    text_string = text_string.strip()[:params.max_string_length]\n",
    "    in_array = np.array([ord(c) for c in text_string], dtype=np.uint8)\n",
    "    return in_array\n",
    "\n",
    "def byte_hot_encoding(byte_codes):\n",
    "    return tf.one_hot(byte_codes, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts a prediction back to a string.\n",
    "def _codes_to_string(codes):\n",
    "    return \"\".join((chr(c) for c in codes))\n",
    "\n",
    "def _argmax_to_string(argmaxes):\n",
    "    return \"\".join((chr(np.argmax(c)) for c in argmaxes))\n",
    "\n",
    "def decode_text(decoded_tensor):\n",
    "    from_max = tf.argmax(decoded_tensor, axis=-1)\n",
    "    return from_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_transform_to_internal(input_data, layer_id):\n",
    "    with tf.variable_scope(\"input_transform_%d\" % layer_id):\n",
    "      layer_outputs = [input_data]\n",
    "      for _ in range(params.model_n):\n",
    "        layer_output = tf.layers.conv1d(layer_outputs[-1],filters=params.conv_n_filters, kernel_size=params.conv_filter_size, padding=\"same\", activation=tf.nn.relu)\n",
    "        layer_output = tf.layers.batch_normalization(layer_output)\n",
    "        if len(layer_outputs) > 2:\n",
    "          # add residual connection\n",
    "          layer_output += layer_outputs[-2]\n",
    "        layer_outputs.append(layer_output)\n",
    "    return layer_outputs[-1]\n",
    "    \n",
    "def encoder_recursion_layer(input_data, layer_id):\n",
    "    processed = encoder_transform_to_internal(input_data, layer_id)\n",
    "    return tf.layers.max_pooling1d(processed, pool_size=2, strides = 2)\n",
    "\n",
    "def encoder_fully_connected(input_data):\n",
    "    with tf.variable_scope(\"encoder_fully_connected\"):\n",
    "        flattened = tf.contrib.layers.flatten(input_data)\n",
    "        layer_size = flattened.get_shape()[-1].value\n",
    "        layers_output = [flattened]\n",
    "        for _ in range(params.model_n):\n",
    "            layer_output = tf.contrib.layers.fully_connected(layers_output[-1], layer_size)\n",
    "            if len(layers_output) > 2:\n",
    "                layer_output += layers_output[-2]\n",
    "            layers_output.append(layer_output)\n",
    "    return layers_output[-1]\n",
    "    \n",
    "\n",
    "def build_encoder(input_data):\n",
    "    data = [encoder_transform_to_internal(input_data, 0)]\n",
    "    for i in range(1, 5):\n",
    "      data.append(encoder_recursion_layer(data[-1], i))\n",
    "    # return encoder_fully_connected(data[-1])    \n",
    "    return data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_fully_connected(input_data):\n",
    "    with tf.variable_scope(\"decoder_fully_connected\"):\n",
    "        layer_size = input_data.get_shape()[-1].value\n",
    "        layer_outputs = [input_data]\n",
    "        for _ in range(params.model_n):\n",
    "            layer_output = tf.contrib.layers.fully_connected(layer_outputs[-1], layer_size)\n",
    "            if len(layer_outputs) > 2:\n",
    "                layer_output += layer_outputs[-2]\n",
    "            layer_outputs.append(layer_output)\n",
    "        # Unflatten data.\n",
    "        output = tf.reshape(layer_outputs[-1], shape=[-1,layer_size/params.conv_n_filters, params.conv_n_filters])\n",
    "    return output\n",
    "\n",
    "def decoder_transform_to_external(input_data, depth, layer_id):\n",
    "    with tf.variable_scope(\"decoder_transform_%d\" % layer_id):\n",
    "      layer_outputs = [input_data]\n",
    "      for _ in range(depth):\n",
    "        layer_output = tf.layers.conv1d(layer_outputs[-1],filters=params.conv_n_filters, kernel_size=params.conv_filter_size, padding=\"same\", activation=tf.nn.relu)\n",
    "        layer_output = tf.layers.batch_normalization(layer_output)\n",
    "        # Extend size \n",
    "        if len(layer_outputs) > 2:\n",
    "          # add residual connection\n",
    "          layer_output += layer_outputs[-2]\n",
    "        layer_outputs.append(layer_output)\n",
    "    return layer_outputs[-1]\n",
    "\n",
    "def decoder_recursion_layer(input_data, layer_id):\n",
    "    with tf.variable_scope(\"decoder_expansion_%d\" % layer_id):\n",
    "        processed = decoder_transform_to_external(input_data, params.model_n-1,layer_id)\n",
    "        # Expand convolution.\n",
    "        expanded = tf.layers.conv1d(processed,filters=2*params.conv_n_filters, kernel_size=params.conv_filter_size, padding=\"same\", activation=tf.nn.relu)\n",
    "        expanded = tf.layers.batch_normalization(expanded)\n",
    "        # Un-sampling is done by resize.\n",
    "        expanded_shape = expanded.get_shape()\n",
    "        expanded = tf.reshape(expanded, shape = [-1,expanded_shape[1].value*2,expanded_shape[2].value/2])\n",
    "        return expanded\n",
    "\n",
    "def build_decoder(output_data):\n",
    "    #data = [decoder_fully_connected(output_data)]\n",
    "    data = [output_data]\n",
    "    for i in range(5,1, -1):\n",
    "        data.append(decoder_recursion_layer(data[-1], i))\n",
    "    return decoder_transform_to_external(data[-1], params.model_n, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Loss 2.51361513138, step 144301 <BR><table>\n",
       "                <tr><th>Source</th><th>Decoded</th></tr><tr><td>When I was 15 years old,  it was necessary for me to leave this </td><td>An                                                      e  this </td></tr><tr><td>And it has two nice fences of tropical hardwood trees --  you ha</td><td>An                                                      e  on hi</td></tr><tr><td>Your work seems to suggest that that is powerfully wrong.\u0000\u0000\u0000\u0000\u0000\u0000\u0000</td><td>Th                                               e thing.\u0000\u0000\u0000\u0000\u0000\u0000\u0000</td></tr><tr><td>Thank you very much. Chris Anderson: That's it?\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000</td><td>Th                                       et it.\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000</td></tr><tr><td>Join us, come into that safe space,  and let's start to make thi</td><td>An                                                       ane thi</td></tr><tr><td>And so that means they need to secure  production and quality co</td><td>An                                                       hite to</td></tr><tr><td>It's -- I had to make little holes  in the base of the needle, t</td><td>An                                                       orly,  </td></tr><tr><td>But they have 40 sensors all over their body.\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000</td><td>Th                                    e lity.\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000</td></tr><tr><td>Seeing people die every day,  my mother crying,  it's like I was</td><td>An                                                        he war</td></tr><tr><td>And that's a project that is just about to open next week,  the </td><td>An                                                       t  the </td></tr><tr><td>But we got this other benefit, and that was  the ability of the </td><td>An                                                       in the </td></tr><tr><td>So I finally decided, I said \"Look,\" --  this is all through the</td><td>An                                                       ate the</td></tr><tr><td>They're failed states.\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000</td><td>Th            e tines.\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000</td></tr><tr><td>A detachable, swimming penis.\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000</td><td>Th                     tiles.\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000</td></tr><tr><td>Hi. So, this chap here,  he thinks he can tell you the future.\u0000\u0000</td><td>An                                                     e ture.\u0000\u0000</td></tr><tr><td>She actually has a Harvard psychiatrist,  and she's been treated</td><td>An                                                         anted</td></tr></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 144315 into ./checkpoint/model.ckpt.\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    dataset = tf.contrib.data.TextLineDataset(\"train.en\")\n",
    "    dataset = dataset.repeat(params.num_epochs)\n",
    "    dataset = dataset.shuffle(params.shuffle_buffer)\n",
    "    dataset = dataset.map(lambda text_string: tf.py_func(_text_to_codes,[text_string], tf.uint8))\n",
    "    dataset = dataset.padded_batch(params.batch_size, [params.max_string_length])\n",
    "    dataset = dataset.map(byte_hot_encoding)\n",
    "    training_iterator = dataset.make_initializable_iterator()\n",
    "    next_element = training_iterator.get_next()\n",
    "    encoded = build_encoder(next_element)\n",
    "    predicted = build_decoder(encoded)\n",
    "    predicted_text = decode_text(predicted)\n",
    "    loss = tf.losses.softmax_cross_entropy(tf.reshape(next_element, shape=[-1,256]), tf.reshape(predicted, shape=[-1, 256]))\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    global_step = tf.Variable(0, trainable=False, name=\"global_step\")\n",
    "    exponential_decay_fn = functools.partial(\n",
    "      tf.train.exponential_decay,\n",
    "      decay_steps=10000,\n",
    "      decay_rate=0.5,\n",
    "      staircase=True)\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        training_op = tf.contrib.layers.optimize_loss(\n",
    "            loss,\n",
    "            global_step,\n",
    "            learning_rate=None,\n",
    "            optimizer=optimizer,\n",
    "            learning_rate_decay_fn=exponential_decay_fn)\n",
    "    scaffold = tf.train.Scaffold(\n",
    "        local_init_op=tf.group(tf.local_variables_initializer(),training_iterator.initializer),\n",
    "        init_op=tf.global_variables_initializer())\n",
    "    with tf.train.MonitoredTrainingSession(checkpoint_dir=\"./checkpoint\",scaffold=scaffold, save_checkpoint_secs=120, save_summaries_secs=60) as sess:\n",
    "        print \"Start training\"\n",
    "        while not sess.should_stop():\n",
    "            o_loss, _, o_step = sess.run([loss, training_op, global_step])\n",
    "            if o_step%100 == 1:\n",
    "                clear_output(True)\n",
    "                output_string = \"\"\"Loss {0}, step {1} <BR><table>\n",
    "                <tr><th>Source</th><th>Decoded</th></tr>\"\"\".format(o_loss, o_step)\n",
    "                o_source_text, o_predicted_text = sess.run([next_element, predicted_text])\n",
    "                for t_source, t_predicted in zip((x for x in o_source_text),(y for y in o_predicted_text)):\n",
    "                    output_string += \"\"\"<tr><td>{source}</td><td>{decoded}</td></tr>\"\"\".format(source=_argmax_to_string(t_source),\n",
    "                                                                                               decoded=_codes_to_string(t_predicted))\n",
    "                output_string += \"</table>\"\n",
    "                display_html(output_string, raw=True)\n",
    "                \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
